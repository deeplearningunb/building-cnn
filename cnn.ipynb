{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36964bit5aff65cb5d064dc4bf8e53621272c904",
   "display_name": "Python 3.6.9 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting tensorflow==1.13.1 (from -r requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/77/63/a9fa76de8dffe7455304c4ed635be4aa9c0bacef6e0633d87d5f54530c5c/tensorflow-1.13.1-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting numpy==1.16.2 (from -r requirements.txt (line 2))\n",
      "  Using cached https://files.pythonhosted.org/packages/35/d5/4f8410ac303e690144f0a0603c4b8fd3b986feb2749c435f7cdbb288f17e/numpy-1.16.2-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting pandas==0.24.2 (from -r requirements.txt (line 3))\n",
      "  Using cached https://files.pythonhosted.org/packages/19/74/e50234bc82c553fecdbd566d8650801e3fe2d6d8c8d940638e3d8a7c5522/pandas-0.24.2-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting matplotlib==3.0.3 (from -r requirements.txt (line 4))\n",
      "  Using cached https://files.pythonhosted.org/packages/e9/69/f5e05f578585ed9935247be3788b374f90701296a70c8871bcd6d21edb00/matplotlib-3.0.3-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting Keras==2.3.0 (from -r requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/1b/18/2e1ef121e5560ac24c7ac9e363aa5fa7006c40563c989e7211aba95b793a/Keras-2.3.0-py2.py3-none-any.whl (377kB)\n",
      "\u001b[K    100% |████████████████████████████████| 378kB 1.2MB/s \n",
      "\u001b[?25hCollecting sklearn==0.0 (from -r requirements.txt (line 6))\n",
      "Collecting six>=1.10.0 (from tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/ee/ff/48bde5c0f013094d729fe4b0316ba2a24774b3ff1c52d924a8a4cb04078a/six-1.15.0-py2.py3-none-any.whl\n",
      "Collecting keras-preprocessing>=1.0.5 (from tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/79/4c/7c3275a01e12ef9368a892926ab932b33bb13d55794881e3573482b378a7/Keras_Preprocessing-1.1.2-py2.py3-none-any.whl\n",
      "Collecting astor>=0.6.0 (from tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/c3/88/97eef84f48fa04fbd6750e62dcceafba6c63c81b7ac1420856c8dcc0a3f9/astor-0.8.1-py2.py3-none-any.whl\n",
      "Collecting protobuf>=3.6.1 (from tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/fe/fd/247ef25f5ec5f9acecfbc98ca3c6aaf66716cf52509aca9a93583d410493/protobuf-3.14.0-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting wheel>=0.26 (from tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/a7/00/3df031b3ecd5444d572141321537080b40c1c25e1caa3d86cdd12e5e919c/wheel-0.35.1-py2.py3-none-any.whl\n",
      "Collecting tensorboard<1.14.0,>=1.13.0 (from tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/0f/39/bdd75b08a6fba41f098b6cb091b9e8c7a80e1b4d679a581a0ccd17b10373/tensorboard-1.13.1-py3-none-any.whl\n",
      "Collecting gast>=0.2.0 (from tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/b6/48/583c032b79ae5b3daa02225a675aeb673e58d2cb698e78510feceb11958c/gast-0.4.0-py3-none-any.whl\n",
      "Collecting tensorflow-estimator<1.14.0rc0,>=1.13.0 (from tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/bb/48/13f49fc3fa0fdf916aa1419013bb8f2ad09674c275b4046d5ee669a46873/tensorflow_estimator-1.13.0-py2.py3-none-any.whl\n",
      "Collecting keras-applications>=1.0.6 (from tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl\n",
      "Collecting termcolor>=1.1.0 (from tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "Collecting absl-py>=0.1.6 (from tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/bc/58/0aa6fb779dc69cfc811df3398fcbeaeefbf18561b6e36b185df0782781cc/absl_py-0.11.0-py3-none-any.whl\n",
      "Collecting grpcio>=1.8.6 (from tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "Collecting pytz>=2011k (from pandas==0.24.2->-r requirements.txt (line 3))\n",
      "  Using cached https://files.pythonhosted.org/packages/12/f8/ff09af6ff61a3efaad5f61ba5facdf17e7722c4393f7d8a66674d2dbd29f/pytz-2020.4-py2.py3-none-any.whl\n",
      "Collecting python-dateutil>=2.5.0 (from pandas==0.24.2->-r requirements.txt (line 3))\n",
      "  Using cached https://files.pythonhosted.org/packages/d4/70/d60450c3dd48ef87586924207ae8907090de0b306af2bce5d134d78615cb/python_dateutil-2.8.1-py2.py3-none-any.whl\n",
      "Collecting cycler>=0.10 (from matplotlib==3.0.3->-r requirements.txt (line 4))\n",
      "  Using cached https://files.pythonhosted.org/packages/f7/d2/e07d3ebb2bd7af696440ce7e754c59dd546ffe1bbe732c8ab68b9c834e61/cycler-0.10.0-py2.py3-none-any.whl\n",
      "Collecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 (from matplotlib==3.0.3->-r requirements.txt (line 4))\n",
      "  Using cached https://files.pythonhosted.org/packages/8a/bb/488841f56197b13700afd5658fc279a2025a39e22449b7cf29864669b15d/pyparsing-2.4.7-py2.py3-none-any.whl\n",
      "Collecting kiwisolver>=1.0.1 (from matplotlib==3.0.3->-r requirements.txt (line 4))\n",
      "  Using cached https://files.pythonhosted.org/packages/a7/1b/cbd8ae738719b5f41592a12057ef5442e2ed5f5cb5451f8fc7e9f8875a1a/kiwisolver-1.3.1-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting pyyaml (from Keras==2.3.0->-r requirements.txt (line 5))\n",
      "Collecting scipy>=0.14 (from Keras==2.3.0->-r requirements.txt (line 5))\n",
      "  Using cached https://files.pythonhosted.org/packages/c8/89/63171228d5ced148f5ced50305c89e8576ffc695a90b58fe5bb602b910c2/scipy-1.5.4-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting h5py (from Keras==2.3.0->-r requirements.txt (line 5))\n",
      "  Using cached https://files.pythonhosted.org/packages/70/7a/e53e500335afb6b1aade11227cdf107fca54106a1dca5c9d13242a043f3b/h5py-3.1.0-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting scikit-learn (from sklearn==0.0->-r requirements.txt (line 6))\n",
      "  Using cached https://files.pythonhosted.org/packages/5c/a1/273def87037a7fb010512bbc5901c31cfddfca8080bc63b42b26e3cc55b3/scikit_learn-0.23.2-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting markdown>=2.6.8 (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/ac/ef/24a91ca96efa0d7802dffb83ccc7a3c677027bea19ec3c9ee80be740408e/Markdown-3.3.3-py3-none-any.whl\n",
      "Collecting werkzeug>=0.11.15 (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/cc/94/5f7079a0e00bd6863ef8f1da638721e9da21e5bacee597595b318f71d62e/Werkzeug-1.0.1-py2.py3-none-any.whl\n",
      "Collecting mock>=2.0.0 (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/cd/74/d72daf8dff5b6566db857cfd088907bb0355f5dd2914c4b3ef065c790735/mock-4.0.2-py3-none-any.whl\n",
      "Collecting cached-property; python_version < \"3.8\" (from h5py->Keras==2.3.0->-r requirements.txt (line 5))\n",
      "  Using cached https://files.pythonhosted.org/packages/48/19/f2090f7dad41e225c7f2326e4cfe6fff49e57dedb5b53636c9551f86b069/cached_property-1.5.2-py2.py3-none-any.whl\n",
      "Collecting joblib>=0.11 (from scikit-learn->sklearn==0.0->-r requirements.txt (line 6))\n",
      "  Using cached https://files.pythonhosted.org/packages/fc/c9/f58220ac44a1592f79a343caba12f6837f9e0c04c196176a3d66338e1ea8/joblib-0.17.0-py3-none-any.whl\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn->sklearn==0.0->-r requirements.txt (line 6))\n",
      "  Using cached https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
      "Collecting importlib-metadata; python_version < \"3.8\" (from markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/6d/6d/f4bb28424bc677bce1210bc19f69a43efe823e294325606ead595211f93e/importlib_metadata-2.0.0-py2.py3-none-any.whl\n",
      "Collecting zipp>=0.5 (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1->-r requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/41/ad/6a4f1a124b325618a7fb758b885b68ff7b058eec47d9220a12ab38d90b1f/zipp-3.4.0-py3-none-any.whl\n",
      "Installing collected packages: six, numpy, keras-preprocessing, astor, protobuf, wheel, absl-py, grpcio, zipp, importlib-metadata, markdown, werkzeug, tensorboard, gast, mock, tensorflow-estimator, cached-property, h5py, keras-applications, termcolor, tensorflow, pytz, python-dateutil, pandas, cycler, pyparsing, kiwisolver, matplotlib, pyyaml, scipy, Keras, joblib, threadpoolctl, scikit-learn, sklearn\n",
      "Successfully installed Keras-2.4.3 absl-py-0.11.0 astor-0.8.1 cached-property-1.5.2 cycler-0.10.0 gast-0.4.0 grpcio-1.33.2 h5py-3.1.0 importlib-metadata-2.0.0 joblib-0.17.0 keras-applications-1.0.8 keras-preprocessing-1.1.2 kiwisolver-1.3.1 markdown-3.3.3 matplotlib-3.3.3 mock-4.0.2 numpy-1.16.2 pandas-0.24.2 protobuf-3.14.0 pyparsing-2.4.7 python-dateutil-2.8.1 pytz-2020.4 pyyaml-5.3.1 scikit-learn-0.23.2 scipy-1.5.4 six-1.15.0 sklearn-0.0 tensorboard-1.13.1 tensorflow-1.13.1 tensorflow-estimator-1.13.0 termcolor-1.1.0 threadpoolctl-2.1.0 werkzeug-1.0.1 wheel-0.35.1 zipp-3.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Convolutional Neural Network\n",
    "\n",
    "# Part 1 - Building the CNN\n",
    "\n",
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From /home/paulo/.local/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Initialising the CNN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Step 1 - Convolution\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))\n",
    "\n",
    "# Step 2 - Pooling\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Adding a second convolutional layer\n",
    "classifier.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Adding a third convolutional layer\n",
    "classifier.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Step 3 - Flattening\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Step 4 - Full connection\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(Dense(units = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the CNN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2 - Fitting the CNN to the images\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 8000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory('dataset/training_set',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_set = test_datagen.flow_from_directory('dataset/test_set',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From /home/paulo/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/5\n",
      "8000/8000 [==============================] - 1803s 225ms/step - loss: 0.3698 - accuracy: 0.8234 - val_loss: 0.3582 - val_accuracy: 0.8406\n",
      "Epoch 2/5\n",
      "8000/8000 [==============================] - 1630s 204ms/step - loss: 0.1170 - accuracy: 0.9545 - val_loss: 0.5531 - val_accuracy: 0.8282\n",
      "Epoch 3/5\n",
      "8000/8000 [==============================] - 1640s 205ms/step - loss: 0.0576 - accuracy: 0.9791 - val_loss: 0.3951 - val_accuracy: 0.8429\n",
      "Epoch 4/5\n",
      "8000/8000 [==============================] - 1758s 220ms/step - loss: 0.0427 - accuracy: 0.9847 - val_loss: 0.5700 - val_accuracy: 0.8231\n",
      "Epoch 5/5\n",
      "8000/8000 [==============================] - 1684s 211ms/step - loss: 0.0345 - accuracy: 0.9879 - val_loss: 0.6357 - val_accuracy: 0.8377\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fb894f20c18>"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "classifier.fit_generator(training_set,\n",
    "                         steps_per_epoch = 8000,\n",
    "                         epochs = 5,\n",
    "                         validation_data = test_set,\n",
    "                         validation_steps = 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 29, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 12, 12, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               295040    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 323,809\n",
      "Trainable params: 323,809\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[1.3822726011276245, 0.8375377655029297]"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "classifier.evaluate_generator(generator=test_set, steps=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, metric = classifier.evaluate_generator(generator=test_set, steps=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loss: 1.0186251401901245\nacc: 0.8375535607337952\n"
     ]
    }
   ],
   "source": [
    "print('loss:', loss)\n",
    "print('acc:', metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}