{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3DR-eO17geWu"
   },
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EMefrVPCg-60"
   },
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.6.0-cp39-cp39-win_amd64.whl (423.3 MB)\n",
      "Collecting keras\n",
      "  Downloading keras-2.6.0-py2.py3-none-any.whl (1.3 MB)\n",
      "Collecting Pillow\n",
      "  Downloading Pillow-8.3.1-1-cp39-cp39-win_amd64.whl (3.2 MB)\n",
      "Collecting google-pasta~=0.2\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied, skipping upgrade: numpy~=1.19.2 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (1.19.3)\n",
      "Requirement already satisfied, skipping upgrade: six~=1.15.0 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: typing-extensions~=3.7.4 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (3.7.4.3)\n",
      "Collecting absl-py~=0.10\n",
      "  Downloading absl_py-0.13.0-py3-none-any.whl (132 kB)\n",
      "Collecting grpcio<2.0,>=1.37.0\n",
      "  Downloading grpcio-1.39.0-cp39-cp39-win_amd64.whl (3.2 MB)\n",
      "Collecting protobuf>=3.9.2\n",
      "  Downloading protobuf-3.17.3-cp39-cp39-win_amd64.whl (909 kB)\n",
      "Collecting tensorflow-estimator~=2.6\n",
      "  Downloading tensorflow_estimator-2.6.0-py2.py3-none-any.whl (462 kB)\n",
      "Collecting opt-einsum~=3.3.0\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting clang~=5.0\n",
      "  Downloading clang-5.0.tar.gz (30 kB)\n",
      "Collecting flatbuffers~=1.12.0\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting gast==0.4.0\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting keras-preprocessing~=1.1.2\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting astunparse~=1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting termcolor~=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting h5py~=3.1.0\n",
      "  Downloading h5py-3.1.0-cp39-cp39-win_amd64.whl (2.7 MB)\n",
      "Collecting wheel~=0.35\n",
      "  Downloading wheel-0.37.0-py2.py3-none-any.whl (35 kB)\n",
      "Collecting wrapt~=1.12.1\n",
      "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
      "Collecting tensorboard~=2.6\n",
      "  Downloading tensorboard-2.6.0-py3-none-any.whl (5.6 MB)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (49.2.1)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.35.0-py2.py3-none-any.whl (152 kB)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (1.0.1)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.5-py2.py3-none-any.whl (18 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
      "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.25.1)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting rsa<5,>=3.1.4; python_version >= \"3.6\"\n",
      "  Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.2-py3-none-any.whl (11 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.10)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2020.12.5)\n",
      "Requirement already satisfied, skipping upgrade: chardet<5,>=3.0.2 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.27,>=1.21.1 in c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.26.2)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\n",
      "Using legacy 'setup.py install' for clang, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for termcolor, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for wrapt, since package 'wheel' is not installed.\n",
      "Installing collected packages: google-pasta, absl-py, grpcio, protobuf, tensorflow-estimator, opt-einsum, clang, flatbuffers, gast, keras-preprocessing, keras, wheel, astunparse, termcolor, h5py, wrapt, pyasn1, pyasn1-modules, rsa, cachetools, google-auth, tensorboard-plugin-wit, tensorboard-data-server, oauthlib, requests-oauthlib, google-auth-oauthlib, markdown, tensorboard, tensorflow, Pillow\n",
      "    Running setup.py install for clang: started\n",
      "    Running setup.py install for clang: finished with status 'done'\n",
      "    Running setup.py install for termcolor: started\n",
      "    Running setup.py install for termcolor: finished with status 'done'\n",
      "    Running setup.py install for wrapt: started\n",
      "    Running setup.py install for wrapt: finished with status 'done'\n",
      "Successfully installed Pillow-8.3.1 absl-py-0.13.0 astunparse-1.6.3 cachetools-4.2.2 clang-5.0 flatbuffers-1.12 gast-0.4.0 google-auth-1.35.0 google-auth-oauthlib-0.4.5 google-pasta-0.2.0 grpcio-1.39.0 h5py-3.1.0 keras-2.6.0 keras-preprocessing-1.1.2 markdown-3.3.4 oauthlib-3.1.1 opt-einsum-3.3.0 protobuf-3.17.3 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.7.2 tensorboard-2.6.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.0 tensorflow-2.6.0 tensorflow-estimator-2.6.0 termcolor-1.1.0 wheel-0.37.0 wrapt-1.12.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the 'c:\\users\\lucas\\appdata\\local\\programs\\python\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip3 install --upgrade tensorflow keras Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sCV30xyVhFbE"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\r\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FIleuCAjoFD8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oxQxCBWyoGPE"
   },
   "source": [
    "## Part 1 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MvE-heJNo3GG"
   },
   "source": [
    "### Preprocessing the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0koUcJMJpEBD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# https://fairyonice.github.io/Learn-about-ImageDataGenerator.html\r\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\r\n",
    "\r\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,         # Rescala imagem\r\n",
    "                                   shear_range = 0.2,        # Aplica um efeito de rotação\r\n",
    "                                   zoom_range = 0.2,         # Aplica um zoom a imagem, com intensidades variadas\r\n",
    "                                   horizontal_flip = True,   # Espelha imagem\r\n",
    "                                   # Adicionados\r\n",
    "                                   #rotation_range=20,        # Rotacao aleatoria de X graus\r\n",
    "                                   width_shift_range=0.2)   # Move a imagem para os lados\r\n",
    "\r\n",
    "training_set = train_datagen.flow_from_directory('dataset/training_set',\r\n",
    "                                                 target_size = (64, 64),\r\n",
    "                                                 batch_size = 64,  # Alterado de 32 para 64\r\n",
    "                                                 class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mrCMmGw9pHys"
   },
   "source": [
    "### Preprocessing the Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SH4WzfOhpKc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255)\r\n",
    "test_set = test_datagen.flow_from_directory('dataset/test_set',\r\n",
    "                                            target_size = (64, 64),\r\n",
    "                                            batch_size = 6,  # Alterado de 32 para 64 \r\n",
    "                                            class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "af8O4l90gk7B"
   },
   "source": [
    "## Part 2 - Building the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ces1gXY2lmoX"
   },
   "source": [
    "### Initialising the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SAUt4UMPlhLS"
   },
   "outputs": [],
   "source": [
    "cnn = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u5YJj_XMl5LF"
   },
   "source": [
    "### Step 1 - Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XPzPrMckl-hV"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tf87FpvxmNOJ"
   },
   "source": [
    "### Step 2 - Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ncpqPl69mOac"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xaTOgD8rm4mU"
   },
   "source": [
    "### Adding a second convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i_-FZjn_m8gk"
   },
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D\r\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\r\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tmiEuvTunKfk"
   },
   "source": [
    "### Step 3 - Flattening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6AZeOGCvnNZn"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dAoSECOm203v"
   },
   "source": [
    "### Step 4 - Full Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8GtmUlLd26Nq"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=256, activation='relu')) # Alterado units de 126 para 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yTldFvbX28Na"
   },
   "source": [
    "### Step 5 - Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1p_Zj1Mc3Ko_"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D6XkI90snSDl"
   },
   "source": [
    "## Part 3 - Training the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vfrFQACEnc6i"
   },
   "source": [
    "### Compiling the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NALksrNQpUlJ"
   },
   "outputs": [],
   "source": [
    "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ehS-v3MIpX2h"
   },
   "source": [
    "### Training the CNN on the Training set and evaluating it on the Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XUj1W4PJptta"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "125/125 [==============================] - 27s 215ms/step - loss: 0.6713 - accuracy: 0.5681 - val_loss: 0.6892 - val_accuracy: 0.5535\n",
      "Epoch 2/30\n",
      "125/125 [==============================] - 26s 210ms/step - loss: 0.6037 - accuracy: 0.6758 - val_loss: 0.5649 - val_accuracy: 0.7200\n",
      "Epoch 3/30\n",
      "125/125 [==============================] - 26s 209ms/step - loss: 0.5741 - accuracy: 0.6952 - val_loss: 0.6043 - val_accuracy: 0.6810\n",
      "Epoch 4/30\n",
      "125/125 [==============================] - 27s 214ms/step - loss: 0.5505 - accuracy: 0.7188 - val_loss: 0.5197 - val_accuracy: 0.7490\n",
      "Epoch 5/30\n",
      "125/125 [==============================] - 27s 214ms/step - loss: 0.5337 - accuracy: 0.7308 - val_loss: 0.5264 - val_accuracy: 0.7320\n",
      "Epoch 6/30\n",
      "125/125 [==============================] - 26s 208ms/step - loss: 0.5191 - accuracy: 0.7409 - val_loss: 0.5829 - val_accuracy: 0.7000\n",
      "Epoch 7/30\n",
      "125/125 [==============================] - 26s 209ms/step - loss: 0.5055 - accuracy: 0.7541 - val_loss: 0.4688 - val_accuracy: 0.7775\n",
      "Epoch 8/30\n",
      "125/125 [==============================] - 26s 211ms/step - loss: 0.4899 - accuracy: 0.7589 - val_loss: 0.4727 - val_accuracy: 0.7770\n",
      "Epoch 9/30\n",
      "125/125 [==============================] - 26s 211ms/step - loss: 0.4896 - accuracy: 0.7635 - val_loss: 0.5875 - val_accuracy: 0.7230\n",
      "Epoch 10/30\n",
      "125/125 [==============================] - 26s 207ms/step - loss: 0.4818 - accuracy: 0.7679 - val_loss: 0.4652 - val_accuracy: 0.7760\n",
      "Epoch 11/30\n",
      "125/125 [==============================] - 26s 207ms/step - loss: 0.4675 - accuracy: 0.7751 - val_loss: 0.4805 - val_accuracy: 0.7735\n",
      "Epoch 12/30\n",
      "125/125 [==============================] - 25s 203ms/step - loss: 0.4596 - accuracy: 0.7828 - val_loss: 0.4414 - val_accuracy: 0.7980\n",
      "Epoch 13/30\n",
      "125/125 [==============================] - 25s 202ms/step - loss: 0.4592 - accuracy: 0.7791 - val_loss: 0.4517 - val_accuracy: 0.7905\n",
      "Epoch 14/30\n",
      "125/125 [==============================] - 25s 204ms/step - loss: 0.4502 - accuracy: 0.7851 - val_loss: 0.4598 - val_accuracy: 0.7895\n",
      "Epoch 15/30\n",
      "125/125 [==============================] - 25s 203ms/step - loss: 0.4458 - accuracy: 0.7906 - val_loss: 0.4573 - val_accuracy: 0.7930\n",
      "Epoch 16/30\n",
      "125/125 [==============================] - 25s 202ms/step - loss: 0.4417 - accuracy: 0.7869 - val_loss: 0.4220 - val_accuracy: 0.8125\n",
      "Epoch 17/30\n",
      "125/125 [==============================] - 25s 203ms/step - loss: 0.4339 - accuracy: 0.7955 - val_loss: 0.4315 - val_accuracy: 0.8055\n",
      "Epoch 18/30\n",
      "125/125 [==============================] - 25s 203ms/step - loss: 0.4218 - accuracy: 0.7975 - val_loss: 0.5279 - val_accuracy: 0.7390\n",
      "Epoch 19/30\n",
      "125/125 [==============================] - 25s 202ms/step - loss: 0.4222 - accuracy: 0.8018 - val_loss: 0.4285 - val_accuracy: 0.8125\n",
      "Epoch 20/30\n",
      "125/125 [==============================] - 25s 201ms/step - loss: 0.4226 - accuracy: 0.8048 - val_loss: 0.4524 - val_accuracy: 0.7985\n",
      "Epoch 21/30\n",
      "125/125 [==============================] - 25s 202ms/step - loss: 0.4039 - accuracy: 0.8154 - val_loss: 0.4115 - val_accuracy: 0.8110\n",
      "Epoch 22/30\n",
      "125/125 [==============================] - 25s 202ms/step - loss: 0.4035 - accuracy: 0.8150 - val_loss: 0.4390 - val_accuracy: 0.8060\n",
      "Epoch 23/30\n",
      "125/125 [==============================] - 26s 212ms/step - loss: 0.3982 - accuracy: 0.8174 - val_loss: 0.4370 - val_accuracy: 0.7990\n",
      "Epoch 24/30\n",
      "125/125 [==============================] - 27s 218ms/step - loss: 0.3916 - accuracy: 0.8163 - val_loss: 0.4068 - val_accuracy: 0.8290\n",
      "Epoch 25/30\n",
      "125/125 [==============================] - 26s 210ms/step - loss: 0.3912 - accuracy: 0.8216 - val_loss: 0.4148 - val_accuracy: 0.8205\n",
      "Epoch 26/30\n",
      "125/125 [==============================] - 26s 204ms/step - loss: 0.3833 - accuracy: 0.8269 - val_loss: 0.4353 - val_accuracy: 0.8020\n",
      "Epoch 27/30\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 0.3713 - accuracy: 0.8315 - val_loss: 0.4002 - val_accuracy: 0.8255\n",
      "Epoch 28/30\n",
      "125/125 [==============================] - 25s 203ms/step - loss: 0.3823 - accuracy: 0.8269 - val_loss: 0.4425 - val_accuracy: 0.8025\n",
      "Epoch 29/30\n",
      "125/125 [==============================] - 26s 207ms/step - loss: 0.3632 - accuracy: 0.8357 - val_loss: 0.4230 - val_accuracy: 0.8195\n",
      "Epoch 30/30\n",
      "125/125 [==============================] - 26s 206ms/step - loss: 0.3719 - accuracy: 0.8309 - val_loss: 0.4039 - val_accuracy: 0.8270\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2704f387d60>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(x = training_set, validation_data = test_set, epochs = 30) # Alterado de 25 para 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U3PZasO0006Z"
   },
   "source": [
    "## Part 4 - Making a single prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gsSiWEJY1BPB"
   },
   "outputs": [],
   "source": [
    "import numpy as np\r\n",
    "from keras.preprocessing import image\r\n",
    "test_image = image.load_img('dataset/single_prediction/cat_or_dog_2.jpg', target_size = (64, 64))\r\n",
    "test_image = image.img_to_array(test_image)\r\n",
    "test_image = np.expand_dims(test_image, axis = 0)\r\n",
    "result = cnn.predict(test_image)\r\n",
    "training_set.class_indices\r\n",
    "if result[0][0] == 1:\r\n",
    "  prediction = 'dog'\r\n",
    "else:\r\n",
    "  prediction = 'cat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ED9KB3I54c1i"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n"
     ]
    }
   ],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fim"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "convolutional_neural_network.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "interpreter": {
   "hash": "fd578b525fe7fcca8a3ea11350d18bcbeb29af20bd1df15f6c5fd2c9cf111483"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}